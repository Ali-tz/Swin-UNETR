{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWIN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SwinConfig, SwinModel\n",
    "from transformers import AutoImageProcessor, SwinModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoImageProcessor, SwinForMaskedImageModeling\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoImageProcessor, SwinForImageClassification\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoImageProcessor, TFSwinModel\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoImageProcessor, TFSwinForMaskedImageModeling\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from transformers import AutoImageProcessor, TFSwinForImageClassification\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SwinModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Swin microsoft/swin-tiny-patch4-window7-224 style configuration\n",
    "configuration = SwinConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the microsoft/swin-tiny-patch4-window7-224 style configuration\n",
    "model = SwinModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SwinForMaskedImageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "model = SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-base-simmim-window6-192\")\n",
    "model = SwinForMaskedImageModeling.from_pretrained(\"microsoft/swin-base-simmim-window6-192\")\n",
    "\n",
    "num_patches = (model.config.image_size // model.config.patch_size) ** 2\n",
    "pixel_values = image_processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "# create random boolean mask of shape (batch_size, num_patches)\n",
    "bool_masked_pos = torch.randint(low=0, high=2, size=(1, num_patches)).bool()\n",
    "\n",
    "outputs = model(pixel_values, bool_masked_pos=bool_masked_pos)\n",
    "loss, reconstructed_pixel_values = outputs.loss, outputs.reconstruction\n",
    "list(reconstructed_pixel_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SwinForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "model = SwinForImageClassification.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_label = logits.argmax(-1).item()\n",
    "print(model.config.id2label[predicted_label])\n",
    "\n",
    "# ## TFSwinModel\n",
    "from transformers import AutoImageProcessor, TFSwinModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "model = TFSwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"tf\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFSwinForMaskedImageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "model = TFSwinForMaskedImageModeling.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "\n",
    "num_patches = (model.config.image_size // model.config.patch_size) ** 2\n",
    "pixel_values = image_processor(images=image, return_tensors=\"tf\").pixel_values\n",
    "# create random boolean mask of shape (batch_size, num_patches)\n",
    "bool_masked_pos = tf.random.uniform((1, num_patches)) >= 0.5\n",
    "\n",
    "outputs = model(pixel_values, bool_masked_pos=bool_masked_pos)\n",
    "loss, reconstructed_pixel_values = outputs.loss, outputs.reconstruction\n",
    "list(reconstructed_pixel_values.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFSwinForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "model = TFSwinForImageClassification.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"tf\")\n",
    "logits = model(**inputs).logits\n",
    "\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_label = int(tf.math.argmax(logits, axis=-1))\n",
    "print(model.config.id2label[predicted_label])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
